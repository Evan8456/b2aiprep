{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEx:\\n{\\n    \"adhd_session_id\": {\\n        \"description\": \"Unique identifier for the ADHD session.\"\\n    }\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  [assessment_name]: {\n",
    "    \"description\": [description text],\n",
    "    \"url\": [reproschema_url],\n",
    "    \"data elements\": {\n",
    "       [element_name]: {\n",
    "          'description': [description text],\n",
    "          'datatype': <type>,\n",
    "          'choices': [\n",
    "             [choice name],\n",
    "             [another choice name],\n",
    "           ],\n",
    "           'termURL': [reproschema_url]\n",
    "       }\n",
    "     } \n",
    "   }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Ex now:\n",
    "{\n",
    "    \"adhd_session_id\": {\n",
    "        \"description\": \"Unique identifier for the ADHD session.\"\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "#dict of non-items only that match\n",
    "#list of keys that don't correspond to any reproschema files\n",
    "#\n",
    "# def\n",
    "# for each phenotype jsons\n",
    "#   open as dict\n",
    "#   for each key\n",
    "#       recursively search reproschema for item files that match\n",
    "#       if found at least one:\n",
    "#           if at least one type item\n",
    "#               then populate data\n",
    "#           else\n",
    "#              add to list of non-items only that match \n",
    "#       else:\n",
    "#           add to list of keys that don't correspond to any reproschema files\n",
    "#\n",
    "# def populate data\n",
    "#           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def search_string_in_json_files(directory, search_string):\n",
    "    matching_files = []  # List to store paths of matching JSON files\n",
    "\n",
    "    # Walk through each directory and file in the given directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for phenotype_file_name in files:\n",
    "            file_path = os.path.join(root, phenotype_file_name)\n",
    "            try:\n",
    "                # Attempt to open and load the file as JSON\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)  # Load JSON data\n",
    "                    # Check if the search string is present in the JSON content\n",
    "                    if search_string in str(data):\n",
    "                        matching_files.append(file_path)\n",
    "            except Exception:\n",
    "                # Skip files that cannot be read or loaded as JSON\n",
    "                continue\n",
    "    \n",
    "    return matching_files  # Return the list of matching file paths\n",
    "# search_string = \"adhd_session_id\"\n",
    "# directory = \"/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_adhd_adult/items\"\n",
    "# search_string_in_json_files(directory, search_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def set_data_element():\n",
    "def populate_data_element(phenotype_file_dict, key, item_file_path, phenotype_file_name):\n",
    "    with open(item_file_path, 'r', encoding='utf-8') as file:\n",
    "        reproschema_item = json.load(file)\n",
    "    if not phenotype_file_dict[key] or not isinstance(phenotype_file_dict[key], dict):\n",
    "        phenotype_file_dict[key] = {}\n",
    "    phenotype_file_dict[key][\"question\"] = reproschema_item[\"question\"]\n",
    "\n",
    "    phenotype_file_dict[key][\"datatype\"] = reproschema_item[\"responseOptions\"][\"valueType\"]\n",
    "\n",
    "    if \"choices\" in reproschema_item[\"responseOptions\"]:\n",
    "        phenotype_file_dict[key][\"choices\"] = reproschema_item[\"responseOptions\"][\"choices\"]\n",
    "    else:\n",
    "        phenotype_file_dict[key][\"choices\"] = None\n",
    "    \n",
    "    #TODO add URL\n",
    "\n",
    "    # phenotype_file_dict[phenotype_file_name][\"\"] = # question field\n",
    "\n",
    "        #       'description': [description text],\n",
    "        #   'datatype': <type>,\n",
    "        #   'choices': [\n",
    "        #      [choice name],\n",
    "        #      [another choice name],\n",
    "        #    ],\n",
    "        #    'termURL': [reproschema_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "matching_non_item_files = {}\n",
    "multiple_item_files = []\n",
    "non_matching = []\n",
    "\n",
    "# Specify the phenotype_dir containing the .json files\n",
    "phenotype_dir = \"/Users/isaacbevers/sensein/b2ai-wrapper/b2aiprep/src/b2aiprep/prepare/resources/b2ai-data-bids-like-template/phenotype\"\n",
    "b2ai_redcap2rs_activities_dir = \"/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities\"\n",
    "# Dictionary to store the loaded JSON data\n",
    "\n",
    "def main():\n",
    "    # Loop through each file in the phenotype_dir\n",
    "    for phenotype_file_name in os.listdir(phenotype_dir):\n",
    "        # Check if the file ends with .json and is not \"<measurement_tool_name>.json\"\n",
    "        if phenotype_file_name.endswith(\".json\") and phenotype_file_name != \"<measurement_tool_name>.json\":\n",
    "            file_path = os.path.join(phenotype_dir, phenotype_file_name)\n",
    "\n",
    "            # Open and load the JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                phenotype_file_dict = json.load(file)\n",
    "        \n",
    "            phenotype_file_dict[\"data_elements\"] = {}\n",
    "            for key in phenotype_file_dict:\n",
    "                file_paths = search_string_in_json_files(b2ai_redcap2rs_activities_dir, key)\n",
    "                if file_paths:\n",
    "                    item_file_paths = [path for path in file_paths if \"item\" in path]\n",
    "                    if item_file_paths and len(item_file_paths) == 1:\n",
    "                        populate_data_element(phenotype_file_dict, key, item_file_paths[0], phenotype_file_name)\n",
    "                    elif item_file_paths and len(item_file_paths) > 1:\n",
    "                        # select the correct one\n",
    "                        for path in item_file_paths:\n",
    "                            if os.path.basename(path) == key:\n",
    "                                populate_data_element(phenotype_file_dict, key, path, phenotype_file_name)\n",
    "                        multiple_item_files.append(item_file_paths)\n",
    "                    else:\n",
    "                        matching_non_item_files[key] = file_paths\n",
    "                else:\n",
    "                    non_matching.append(key)\n",
    "\n",
    "            # TODO\n",
    "            # phenotype_file_dict[phenotype_file_name][\"url\"] = \n",
    "            #phenotype_file_dict[phenotype_file_name][data elements] = \n",
    "            # if phenotype_file_name not in phenotype_file_dict:\n",
    "            #     phenotype_file_dict = {phenotype_file_name: RS ASSESSMENT NAME}\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                json.dump(phenotype_file_dict, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "            # save data\n",
    "\n",
    "#       if found at least one:\n",
    "#           if at least one type item\n",
    "#               then populate data\n",
    "#           else\n",
    "#              add to list of non-items only that match \n",
    "#       else:\n",
    "#           add to list of keys that don't correspond to any reproschema files\n",
    "        \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vhi10.json': 11, 'vocalFoldParalysis.json': 1, 'alzheimers.json': 23, 'confounders.json': 125, 'demographics.json': 31, 'panas.json': 8, 'bipolar.json': 1, 'dsm5.json': 33, 'airwaystenosis.json': 16, 'enrollment.json': 22, 'parkinsons.json': 31, 'stroop.json': 1, 'laryngealCancer.json': 25, 'adhd.json': 14, 'winograd.json': 1, 'voicePerception.json': 1, 'gad7.json': 8, 'random.json': 1, 'voiceSeverity.json': 1, 'precancerousLesions.json': 20, 'customAffectScale.json': 13, 'depression.json': 1, 'laryngealDystonia.json': 24, 'als.json': 25, 'dyspnea.json': 11, 'vocab.json': 1, 'eligibility.json': 32, 'phq9.json': 10, 'leicester.json': 20, 'benignLesion.json': 5, 'participant.json': 215, 'ptsd.json': 8}\n",
      "739\n"
     ]
    }
   ],
   "source": [
    "phenotype_dir = \"/Users/isaacbevers/sensein/b2ai-wrapper/b2aiprep/src/b2aiprep/prepare/resources/b2ai-data-bids-like-template/phenotype\"\n",
    "\n",
    "def count_items_with_only_descriptions():\n",
    "    single_entry_fields = {}\n",
    "    for phenotype_file_name in os.listdir(phenotype_dir):\n",
    "        if phenotype_file_name.endswith(\".json\") and phenotype_file_name != \"<measurement_tool_name>.json\":\n",
    "            single_entry_fields[phenotype_file_name] = []\n",
    "            file_path = os.path.join(phenotype_dir, phenotype_file_name)\n",
    "\n",
    "            # Open and load the JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                phenotype_file_dict = json.load(file)\n",
    "\n",
    "            for key in phenotype_file_dict:\n",
    "                if len(phenotype_file_dict[key]) < 2:\n",
    "                    single_entry_fields[phenotype_file_name].append(key)\n",
    "            \n",
    "    single_entry_fields_count = 0\n",
    "    for key in single_entry_fields:\n",
    "        single_entry_fields_count += len(single_entry_fields[key])\n",
    "        single_entry_fields[key] = len(single_entry_fields[key])\n",
    "    print(single_entry_fields)\n",
    "    print(single_entry_fields_count)\n",
    "\n",
    "count_items_with_only_descriptions()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
