{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEx now:\\n{\\n    \"adhd_session_id\": {\\n        \"description\": \"Unique identifier for the ADHD session.\"\\n    }\\n}\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  [assessment_name]: {\n",
    "    \"description\": [description text],\n",
    "    \"url\": [reproschema_url],\n",
    "    \"data elements\": {\n",
    "       [element_name]: {\n",
    "          'description': [description text],\n",
    "          'datatype': <type>,\n",
    "          'choices': [\n",
    "             [choice name],\n",
    "             [another choice name],\n",
    "           ],\n",
    "           'termURL': [reproschema_url]\n",
    "       }\n",
    "     } \n",
    "   }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Ex now:\n",
    "{\n",
    "    \"adhd_session_id\": {\n",
    "        \"description\": \"Unique identifier for the ADHD session.\"\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "#dict of non-items only that match\n",
    "#list of keys that don't correspond to any reproschema files\n",
    "#\n",
    "# def\n",
    "# for each phenotype jsons\n",
    "#   open as dict\n",
    "#   for each key\n",
    "#       recursively search reproschema for item files that match\n",
    "#       if found at least one:\n",
    "#           if at least one type item\n",
    "#               then populate data\n",
    "#           else\n",
    "#              add to list of non-items only that match \n",
    "#       else:\n",
    "#           add to list of keys that don't correspond to any reproschema files\n",
    "#\n",
    "# def populate data\n",
    "#           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_descriptions = {\n",
    "    \"laryngealDystonia.json\": \"Measures symptoms and characteristics of laryngeal dystonia.\",\n",
    "    \"demographics.json\": \"Measures participant background details.\",\n",
    "    \"adhd.json\": \"Measures attention-related behaviors and symptoms.\",\n",
    "    \"airwaystenosis.json\": \"Measures the severity and characteristics of airway stenosis.\",\n",
    "    \"als.json\": \"Measures symptoms and progression of ALS.\",\n",
    "    \"alzheimers.json\": \"Measures cognitive decline and related symptoms.\",\n",
    "    \"benignLesion.json\": \"Measures features of benign lesions.\",\n",
    "    \"bipolar.json\": \"Measures symptoms and behaviors related to bipolar disorder.\",\n",
    "    \"confounders.json\": \"Measures variables that could impact study outcomes.\",\n",
    "    \"customAffectScale.json\": \"Measures emotional states.\",\n",
    "    \"depression.json\": \"Measures severity and impact of depressive symptoms.\",\n",
    "    \"dsm5.json\": \"Measures criteria according to DSM-5 standards.\",\n",
    "    \"dyspnea.json\": \"Measures the presence and severity of dyspnea.\",\n",
    "    \"eligibility.json\": \"Measures participant eligibility for the study.\",\n",
    "    \"enrollment.json\": \"Measures participant registration details.\",\n",
    "    \"gad7.json\": \"Measures severity of generalized anxiety.\",\n",
    "    \"laryngealCancer.json\": \"Measures characteristics of laryngeal cancer.\",\n",
    "    \"leicester.json\": \"Measures specific health or psychological attributes.\",\n",
    "    \"panas.json\": \"Measures positive and negative affect.\",\n",
    "    \"parkinsons.json\": \"Measures symptoms and progression of Parkinson's disease.\",\n",
    "    \"participant.json\": \"Measures general study-related information.\",\n",
    "    \"phq9.json\": \"Measures severity of depressive symptoms.\",\n",
    "    \"precancerousLesions.json\": \"Measures features of precancerous lesions.\",\n",
    "    \"ptsd.json\": \"Measures trauma-related symptoms.\",\n",
    "    \"random.json\": \"Measures variables for various study purposes.\",\n",
    "    \"stroop.json\": \"Measures cognitive control and processing speed.\",\n",
    "    \"vhi10.json\": \"Measures perceived impact of voice disorders.\",\n",
    "    \"vocab.json\": \"Measures language and word knowledge.\",\n",
    "    \"vocalFoldParalysis.json\": \"Measures characteristics of vocal fold paralysis.\",\n",
    "    \"voicePerception.json\": \"Measures how participants perceive voice quality.\",\n",
    "    \"voiceSeverity.json\": \"Measures the impact and seriousness of voice disorders.\",\n",
    "    \"winograd.json\": \"Measures language comprehension and reasoning.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "b2ai_redcap2rs_activities_dir = \"/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities\"\n",
    "\n",
    "def search_string_in_json_files(directory, search_string):\n",
    "    matching_files = []  # List to store paths of matching JSON files\n",
    "\n",
    "    # Walk through each directory and file in the given directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for phenotype_file_name in files:\n",
    "            file_path = os.path.join(root, phenotype_file_name)\n",
    "            try:\n",
    "                # Attempt to open and load the file as JSON\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)  # Load JSON data\n",
    "                    # Check if the search string is present in the JSON content\n",
    "                    if search_string in str(data) or search_string in str(phenotype_file_name):\n",
    "                        matching_files.append(file_path)\n",
    "            except Exception:\n",
    "                # Skip files that cannot be read or loaded as JSON\n",
    "                continue\n",
    "    return matching_files  # Return the list of matching file paths\n",
    "# search_string_in_json_files(b2ai_redcap2rs_activities_dir, \"hello\")\n",
    "# search_string = \"adhd_session_id\"\n",
    "# directory = \"/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_adhd_adult/items\"\n",
    "# search_string_in_json_files(directory, search_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def is_url_resolvable(url):\n",
    "    \"\"\"\n",
    "    Checks if the URL is resolvable.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The URL to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the URL is resolvable, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False\n",
    "\n",
    "def get_reproschema_raw_url(path, checksum=\"65734f24a32b69ed8dca2e92567cbb580cc0d492\", branch=\"main\"):\n",
    "    \"\"\"\n",
    "    Generates a raw GitHub URL for a file in the project.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the file in the project.\n",
    "        checksum (str): The checksum of the file (default is a specific value).\n",
    "        branch (str): Branch name (default is 'main').\n",
    "\n",
    "    Returns:\n",
    "        str: The raw GitHub URL.\n",
    "    \"\"\"\n",
    "    path = path.split('/b2ai-redcap2rs/', 1)[-1]\n",
    "    url = f\"https://raw.githubusercontent.com/sensein/b2ai-redcap2rs/{checksum}/{path}\"\n",
    "    if is_url_resolvable(url):\n",
    "        return url\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # def set_data_element():\n",
    "# def get_reproschema_raw_url(checksum=\"65734f24a32b69ed8dca2e92567cbb580cc0d492\"):\n",
    "    \n",
    "\n",
    "\n",
    "def populate_data_element(output_phenotype_dict, key, item_file_path, phenotype_file_name):\n",
    "    # print(item_file_path)\n",
    "    with open(item_file_path, 'r', encoding='utf-8') as file:\n",
    "        reproschema_item = json.load(file)\n",
    "    if key not in output_phenotype_dict:\n",
    "        output_phenotype_dict[key] = {}\n",
    "    if \"question\" in reproschema_item:\n",
    "        output_phenotype_dict[key][\"question\"] = reproschema_item[\"question\"]\n",
    "\n",
    "    output_phenotype_dict[key][\"datatype\"] = reproschema_item[\"responseOptions\"][\"valueType\"]\n",
    "\n",
    "    if \"choices\" in reproschema_item[\"responseOptions\"]:\n",
    "        output_phenotype_dict[key][\"choices\"] = reproschema_item[\"responseOptions\"][\"choices\"]\n",
    "    else:\n",
    "        output_phenotype_dict[key][\"choices\"] = None\n",
    "    reproschema_raw_url = get_reproschema_raw_url(item_file_path)\n",
    "    if reproschema_raw_url:\n",
    "        output_phenotype_dict[key][\"termURL\"] = reproschema_raw_url\n",
    "\n",
    "    #TODO add URL\n",
    "\n",
    "    # phenotype_file_dict[phenotype_file_name][\"\"] = # question field\n",
    "\n",
    "        #       'description': [description text],\n",
    "        #   'datatype': <type>,\n",
    "        #   'choices': [\n",
    "        #      [choice name],\n",
    "        #      [another choice name],\n",
    "        #    ],\n",
    "        #    'termURL': [reproschema_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_schema_paths(directory):\n",
    "    schema_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('schema'):\n",
    "                schema_paths.append(os.path.join(root, file))\n",
    "    return schema_paths\n",
    "\n",
    "\n",
    "def get_activity_schema_path(item_path):\n",
    "    activity_dir = os.path.join(item_path.split('/activities/', 1)[0], 'activities', item_path.split('/activities/', 1)[-1].split('/')[0])\n",
    "    schema_paths = []\n",
    "    for root, _, files in os.walk(activity_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('schema'):\n",
    "                schema_paths.append(os.path.join(root, file))\n",
    "    if len(schema_paths) == 1:\n",
    "        return schema_paths[0]\n",
    "    else:\n",
    "        # print(schema_paths)\n",
    "        raise ValueError(f\"Wrong number of schema paths: {len(schema_paths)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_generic_voice_handicap_index_vhi10/q_generic_voice_handicap_index_vhi10_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_voice_unilateral_vocal_fold_paralysis/d_voice_unilateral_vocal_fold_paralysis_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_neuro_alzheimers_disease_mild_cognitive_impairme/d_neuro_alzheimers_disease_mild_cognitive_impairme_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_generic_confounders/q_generic_confounders_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_generic_demographics/q_generic_demographics_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_panas/q_mood_panas_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_mood_bipolar_disorder/d_mood_bipolar_disorder_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_dsm5_adult/q_mood_dsm5_adult_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_resp_airway_stenosis/d_resp_airway_stenosis_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/enrollment_form/enrollment_form_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_neuro_parkinsons_disease/d_neuro_parkinsons_disease_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_neuro_wordcolor_stroop/q_neuro_wordcolor_stroop_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_voice_laryngeal_cancer/d_voice_laryngeal_cancer_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_adhd_adult/q_mood_adhd_adult_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_neuro_winograd_schemas/q_neuro_winograd_schemas_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_generic_voice_perception/q_generic_voice_perception_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_generic_gad7_anxiety/q_generic_gad7_anxiety_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_neuro_random_item_generation/q_neuro_random_item_generation_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_voice_voice_problem_severity/q_voice_voice_problem_severity_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_voice_precancerous_lesions/d_voice_precancerous_lesions_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_custom_affect_scale/q_mood_custom_affect_scale_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_mood_depression_or_major_depressive_disorder/d_mood_depression_or_major_depressive_disorder_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_voice_laryngeal_dystonia/d_voice_laryngeal_dystonia_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_neuro_amyotrophic_lateral_sclerosis_als/d_neuro_amyotrophic_lateral_sclerosis_als_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_resp_dyspnea_index_di/q_resp_dyspnea_index_di_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_neuro_productive_vocabulary/q_neuro_productive_vocabulary_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/subjectparticipant_eligible_studies/subjectparticipant_eligible_studies_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_generic_patient_health_questionnaire9/q_generic_patient_health_questionnaire9_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_resp_leicester_cough_questionnaire_lcq/q_resp_leicester_cough_questionnaire_lcq_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/d_voice_benign_lesions/d_voice_benign_lesions_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/subjectparticipant_basic_information/subjectparticipant_basic_information_schema\n",
      "/Users/isaacbevers/sensein/reproschema-wrapper/b2ai-redcap2rs/activities/q_mood_ptsd_adult/q_mood_ptsd_adult_schema\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "            \n",
    "\n",
    "matching_non_item_files = {}\n",
    "multiple_item_files = []\n",
    "non_matching = []\n",
    "\n",
    "# Specify the phenotype_dir containing the .json files\n",
    "phenotype_dir = \"/Users/isaacbevers/sensein/b2ai-wrapper/b2aiprep/src/b2aiprep/prepare/resources/b2ai-data-bids-like-template/phenotype\"\n",
    "# Dictionary to store the loaded JSON data\n",
    "\n",
    "def main():\n",
    "    # Loop through each file in the phenotype_dir\n",
    "    for phenotype_file_name in os.listdir(phenotype_dir):\n",
    "        # Check if the file ends with .json and is not \"<measurement_tool_name>.json\"\n",
    "        if phenotype_file_name.endswith(\".json\") and phenotype_file_name != \"<measurement_tool_name>.json\":\n",
    "            file_path = os.path.join(phenotype_dir, phenotype_file_name)\n",
    "\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                phenotype_file_dict = json.load(file)\n",
    "\n",
    "            # unnest to make output idempotent\n",
    "            if len(phenotype_file_dict) == 1: \n",
    "                key = next(iter(phenotype_file_dict))\n",
    "                if \"data_elements\" in phenotype_file_dict[key]:\n",
    "                    phenotype_file_dict = phenotype_file_dict[key][\"data_elements\"]\n",
    "\n",
    "            activity_schema_path = \"\"\n",
    "            output_phenotype_dict = copy.deepcopy(phenotype_file_dict) \n",
    "            for key in phenotype_file_dict:\n",
    "                if '___' in key:\n",
    "                    new_key = key.split('___')[0]\n",
    "                    if new_key not in phenotype_file_dict:\n",
    "                        key = new_key\n",
    "                        output_phenotype_dict[key] = {}\n",
    "                \n",
    "                file_paths = search_string_in_json_files(b2ai_redcap2rs_activities_dir, key)\n",
    "                if file_paths:\n",
    "                    item_file_paths = [path for path in file_paths if \"item\" in path]\n",
    "                    if item_file_paths and len(item_file_paths) == 1:\n",
    "                        populate_data_element(output_phenotype_dict, key, item_file_paths[0], phenotype_file_name)\n",
    "                        if not activity_schema_path:\n",
    "                            activity_schema_path = get_activity_schema_path(item_file_paths[0])\n",
    "                    elif item_file_paths and len(item_file_paths) > 1:\n",
    "                        # select the correct one\n",
    "                        for path in item_file_paths:\n",
    "                            if os.path.basename(path) == key:\n",
    "                                if not activity_schema_path:\n",
    "                                    activity_schema_path = get_activity_schema_path(path)\n",
    "                                populate_data_element(output_phenotype_dict, key, path, phenotype_file_name)\n",
    "                        multiple_item_files.append(item_file_paths)\n",
    "                    else:\n",
    "                        matching_non_item_files[key] = file_paths\n",
    "                else:\n",
    "                    non_matching.append(key)\n",
    "            print(activity_schema_path)\n",
    "\n",
    "            activity_schema_name = os.path.basename(activity_schema_path)\n",
    "            output_phenotype_dict = {\"data_elements\": output_phenotype_dict}\n",
    "            output_phenotype_dict[\"description\"] = file_descriptions[phenotype_file_name]\n",
    "            output_phenotype_dict[\"url\"] = get_reproschema_raw_url(activity_schema_path)\n",
    "            output_phenotype_dict = {\n",
    "                    \"description\": output_phenotype_dict[\"description\"],\n",
    "                    \"url\": output_phenotype_dict[\"url\"],\n",
    "                    \"data_elements\": output_phenotype_dict[\"data_elements\"]\n",
    "                }\n",
    "            output_phenotype_dict = {activity_schema_name: output_phenotype_dict}\n",
    "            # output_phenotype_dict = dict(sorted(output_phenotype_dict.items()))\n",
    "            # output_phenotype_dict = dict(sorted(output_phenotype_dict.items(), key=lambda item: len(str(item[1]))))\n",
    "\n",
    "            # TODO\n",
    "            # output_phenotype_dict[phenotype_file_name][\"url\"] = \n",
    "            #phenotype_file_dict[phenotype_file_name][data elements] = \n",
    "            # if phenotype_file_name not in output_phenotype_dict:\n",
    "            #     output_phenotype_dict = {phenotype_file_name: RS ASSESSMENT NAME}\n",
    "            # print(output_phenotype_dict)\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                json.dump(output_phenotype_dict, file, ensure_ascii=False, indent=4)\n",
    "\"\"\"\n",
    "{\n",
    "  [assessment_name]: {\n",
    "    \"description\": [description text],\n",
    "    \"url\": [reproschema_url],\n",
    "    \"data elements\": {\n",
    "\"\"\"\n",
    "            # save data\n",
    "\n",
    "#       if found at least one:\n",
    "#           if at least one type item\n",
    "#               then populate data\n",
    "#           else\n",
    "#              add to list of non-items only that match \n",
    "#       else:\n",
    "#           add to list of keys that don't correspond to any reproschema files\n",
    "        \n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['q_generic_demographics_complete', 'subjectparticipant_eligible_studies_complete']\n",
      "0\n",
      "{}\n",
      "540\n"
     ]
    }
   ],
   "source": [
    "print(len(non_matching))\n",
    "print(non_matching)\n",
    "print(len(matching_non_item_files))\n",
    "print(matching_non_item_files)\n",
    "print(len(multiple_item_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vhi10.json': 0, 'vocalFoldParalysis.json': 0, 'alzheimers.json': 28, 'confounders.json': 135, 'demographics.json': 32, 'panas.json': 0, 'bipolar.json': 0, 'dsm5.json': 0, 'airwaystenosis.json': 19, 'enrollment.json': 27, 'parkinsons.json': 37, 'stroop.json': 0, 'laryngealCancer.json': 29, 'adhd.json': 0, 'winograd.json': 0, 'voicePerception.json': 0, 'gad7.json': 0, 'random.json': 0, 'voiceSeverity.json': 0, 'precancerousLesions.json': 23, 'customAffectScale.json': 0, 'depression.json': 0, 'laryngealDystonia.json': 28, 'als.json': 30, 'dyspnea.json': 0, 'vocab.json': 0, 'eligibility.json': 6, 'phq9.json': 0, 'leicester.json': 0, 'benignLesion.json': 5, 'participant.json': 233, 'ptsd.json': 0}\n",
      "632\n"
     ]
    }
   ],
   "source": [
    "phenotype_dir = \"/Users/isaacbevers/sensein/b2ai-wrapper/b2aiprep/src/b2aiprep/prepare/resources/b2ai-data-bids-like-template/phenotype\"\n",
    "\n",
    "def count_items_with_only_descriptions():\n",
    "    single_entry_fields = {}\n",
    "    for phenotype_file_name in os.listdir(phenotype_dir):\n",
    "        if phenotype_file_name.endswith(\".json\") and phenotype_file_name != \"<measurement_tool_name>.json\":\n",
    "            single_entry_fields[phenotype_file_name] = []\n",
    "            file_path = os.path.join(phenotype_dir, phenotype_file_name)\n",
    "\n",
    "            # Open and load the JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                phenotype_file_dict = json.load(file)\n",
    "\n",
    "            for key in phenotype_file_dict:\n",
    "                if len(phenotype_file_dict[key]) < 2:\n",
    "                    single_entry_fields[phenotype_file_name].append(key)\n",
    "            \n",
    "    single_entry_fields_count = 0\n",
    "    for key in single_entry_fields:\n",
    "        single_entry_fields_count += len(single_entry_fields[key])\n",
    "        single_entry_fields[key] = len(single_entry_fields[key])\n",
    "    print(single_entry_fields)\n",
    "    print(single_entry_fields_count)\n",
    "\n",
    "count_items_with_only_descriptions()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m data_dict_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/isaacbevers/sensein/b2ai-wrapper/bridge2ai-redcap/data/bridge2ai_voice_project_data_dictionary.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m phenotype_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/isaacbevers/sensein/b2ai-wrapper/b2aiprep/src/b2aiprep/prepare/resources/b2ai-data-bids-like-template/phenotype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 43\u001b[0m non_matching_choices \u001b[38;5;241m=\u001b[39m \u001b[43mget_non_matching_response_choices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphenotype_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(non_matching_choices)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mget_non_matching_response_choices\u001b[0;34m(data_dict_path, phenotype_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m phenotype_file \u001b[38;5;129;01min\u001b[39;00m phenotype_files:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(phenotype_path, phenotype_file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 16\u001b[0m         phenotype_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Iterate over each data element in the phenotype JSON\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element_name, element_details \u001b[38;5;129;01min\u001b[39;00m phenotype_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_elements\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Filter the data dictionary for the matching element name\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_non_matching_response_choices(data_dict_path, phenotype_path):\n",
    "    non_matching = []\n",
    "\n",
    "    # Load the data dictionary CSV into a DataFrame\n",
    "    data_dict = pd.read_csv(data_dict_path)\n",
    "\n",
    "    # Get list of all phenotype JSON files\n",
    "    phenotype_files = [file for file in os.listdir(phenotype_path) if file.endswith('.json')]\n",
    "\n",
    "    for phenotype_file in phenotype_files:\n",
    "        with open(os.path.join(phenotype_path, phenotype_file), 'r') as f:\n",
    "            phenotype_data = json.load(f)\n",
    "\n",
    "        # Iterate over each data element in the phenotype JSON\n",
    "        for element_name, element_details in phenotype_data.get(\"data_elements\", {}).items():\n",
    "            # Filter the data dictionary for the matching element name\n",
    "            print(element_name)\n",
    "            print(element_details)\n",
    "            # filtered_data_dict = data_dict[data_dict[\"Variable / Field Name\"] == element_name]\n",
    "\n",
    "            # if filtered_data_dict.empty:\n",
    "            #     continue\n",
    "\n",
    "            # filtered_entry = filtered_data_dict.iloc[0]\n",
    "            # valid_labels = filtered_entry.get(\"Choices, Calculations, OR Slider Labels\", \"\")\n",
    "            # choices = element_details.get(\"choices\", [])\n",
    "\n",
    "            # # Check if choices exist and perform lexical matching\n",
    "            # if choices:\n",
    "            #     for choice in choices:\n",
    "            #         if choice not in valid_labels:\n",
    "            #             non_matching.append(choice)\n",
    "\n",
    "    return non_matching\n",
    "\n",
    "# Example usage\n",
    "data_dict_path = \"/Users/isaacbevers/sensein/b2ai-wrapper/bridge2ai-redcap/data/bridge2ai_voice_project_data_dictionary.csv\"\n",
    "phenotype_path = \"/Users/isaacbevers/sensein/b2ai-wrapper/b2aiprep/src/b2aiprep/prepare/resources/b2ai-data-bids-like-template/phenotype\"\n",
    "non_matching_choices = get_non_matching_response_choices(data_dict_path, phenotype_path)\n",
    "print(non_matching_choices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
